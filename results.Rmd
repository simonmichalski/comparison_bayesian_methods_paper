
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
```

```{r}
library("dplyr")

df_results <- readRDS(file.path("results", "results.rds"))
sim_based_thres <- readRDS(file.path("results", "sim_thres.rds"))
df_recovery <- readRDS(file.path("results", "recovery.rds"))
df_sim_thres_prior <- readRDS(file.path("results", "sim_thres_per_prior_sd.rds"))

# Correlation true-estimated subject-level parameters
data_cor_s_log_k <- summarize(group_by(df_recovery, s_log_k_sd, prior_sd, sample), 
                              correlation = cor(true_s_log_k, median_s_log_k))
median_cor_s_log_k_overall <- median(data_cor_s_log_k$correlation)
iqr_cor_s_log_k_overall <- IQR(data_cor_s_log_k$correlation)
median_cor_s_log_k_0_2 <- median(data_cor_s_log_k$correlation[data_cor_s_log_k$s_log_k_sd == 0.2])
iqr_cor_s_log_k_0_2 <- IQR(data_cor_s_log_k$correlation[data_cor_s_log_k$s_log_k_sd == 0.2])
median_cor_s_log_k_0_51 <- median(data_cor_s_log_k$correlation[data_cor_s_log_k$s_log_k_sd == 0.51])
iqr_cor_s_log_k_0_51 <- IQR(data_cor_s_log_k$correlation[data_cor_s_log_k$s_log_k_sd == 0.51])
median_cor_s_log_k_0_81 <- median(data_cor_s_log_k$correlation[data_cor_s_log_k$s_log_k_sd == 0.81])
iqr_cor_s_log_k_0_81 <- IQR(data_cor_s_log_k$correlation[data_cor_s_log_k$s_log_k_sd == 0.81])

data_cor_log_k <- summarize(group_by(df_recovery, s_log_k_sd, prior_sd, sample), 
                            correlation = cor(true_log_k, median_log_k))
median_cor_log_k_overall <- median(data_cor_log_k$correlation)
iqr_cor_log_k_overall <- IQR(data_cor_log_k$correlation)

# Subject-level parameter shrinkage
sd_estimates_s_log_k <- aggregate(df_recovery, median_s_log_k ~ prior_sd + s_log_k_sd + sample, sd)
sd_true_s_log_k <- aggregate(df_recovery, true_s_log_k ~ prior_sd + s_log_k_sd + sample, sd)
data_shrinkage_s_log_k <- merge(sd_estimates_s_log_k, sd_true_s_log_k, by = c("s_log_k_sd", "prior_sd", "sample"))
data_shrinkage_s_log_k$sd_reduction <- (data_shrinkage_s_log_k$true_s_log_k - data_shrinkage_s_log_k$median_s_log_k) / data_shrinkage_s_log_k$true_s_log_k
mean_shrinkage_overall <- mean(data_shrinkage_s_log_k$sd_reduction)
sd_shrinkage_overall <- sd(data_shrinkage_s_log_k$sd_reduction)
mean_shrinkage_0_2 <- mean(data_shrinkage_s_log_k[data_shrinkage_s_log_k$s_log_k_sd == 0.2, "sd_reduction"])
sd_shrinkage_0_2 <- sd(data_shrinkage_s_log_k[data_shrinkage_s_log_k$s_log_k_sd == 0.2, "sd_reduction"])
mean_shrinkage_0_51 <-mean(data_shrinkage_s_log_k[data_shrinkage_s_log_k$s_log_k_sd == 0.51, "sd_reduction"])
sd_shrinkage_0_51 <-sd(data_shrinkage_s_log_k[data_shrinkage_s_log_k$s_log_k_sd == 0.51, "sd_reduction"])
mean_shrinkage_0_81 <-mean(data_shrinkage_s_log_k[data_shrinkage_s_log_k$s_log_k_sd == 0.81, "sd_reduction"])
sd_shrinkage_0_81 <-sd(data_shrinkage_s_log_k[data_shrinkage_s_log_k$s_log_k_sd == 0.81, "sd_reduction"])
mean_sd_true_0_2 <- mean(sd_true_s_log_k[sd_true_s_log_k$s_log_k_sd == 0.2, "true_s_log_k"])
sd_sd_true_0_2 <- sd(sd_true_s_log_k[sd_true_s_log_k$s_log_k_sd == 0.2, "true_s_log_k"])
mean_sd_true_0_51 <- mean(sd_true_s_log_k[sd_true_s_log_k$s_log_k_sd == 0.51, "true_s_log_k"])
sd_sd_true_0_51 <- sd(sd_true_s_log_k[sd_true_s_log_k$s_log_k_sd == 0.51, "true_s_log_k"])
mean_sd_true_0_81 <- mean(sd_true_s_log_k[sd_true_s_log_k$s_log_k_sd == 0.81, "true_s_log_k"])
sd_sd_true_0_81 <- sd(sd_true_s_log_k[sd_true_s_log_k$s_log_k_sd == 0.81, "true_s_log_k"])
mean_sd_estimates_0_2 <- mean(sd_estimates_s_log_k[sd_estimates_s_log_k$s_log_k_sd == 0.2, "median_s_log_k"])
sd_sd_estimates_0_2 <- sd(sd_estimates_s_log_k[sd_estimates_s_log_k$s_log_k_sd == 0.2, "median_s_log_k"])
mean_sd_estimates_0_51 <- mean(sd_estimates_s_log_k[sd_estimates_s_log_k$s_log_k_sd == 0.51, "median_s_log_k"])
sd_sd_estimates_0_51 <- sd(sd_estimates_s_log_k[sd_estimates_s_log_k$s_log_k_sd == 0.51, "median_s_log_k"])
mean_sd_estimates_0_81 <- mean(sd_estimates_s_log_k[sd_estimates_s_log_k$s_log_k_sd == 0.81, "median_s_log_k"])
sd_sd_estimates_0_81 <- sd(sd_estimates_s_log_k[sd_estimates_s_log_k$s_log_k_sd == 0.81, "median_s_log_k"])

sd_estimates_log_k <- aggregate(df_recovery, median_log_k ~ prior_sd + s_log_k_sd + sample, sd)
sd_true_log_k <- aggregate(df_recovery, true_log_k ~ prior_sd + s_log_k_sd + sample, sd)
data_shrinkage_log_k <- merge(sd_estimates_log_k, sd_true_log_k, by = c("s_log_k_sd", "prior_sd", "sample"))
data_shrinkage_log_k$sd_reduction <- (data_shrinkage_log_k$true_log_k - data_shrinkage_log_k$median_log_k) / data_shrinkage_log_k$true_log_k
mean_shrinkage_overall_log_k <- mean(data_shrinkage_log_k$sd_reduction)
sd_shrinkage_overall_log_k <- sd(data_shrinkage_log_k$sd_reduction)
mean_sd_true_overall_log_k <- mean(sd_true_log_k$true_log_k)
sd_sd_true_overall_log_k <- sd(sd_true_log_k$true_log_k)
mean_sd_estimates_overall_log_k <- mean(sd_estimates_log_k$median_log_k)
sd_sd_estimates_overall_log_k <- sd(sd_estimates_log_k$median_log_k)

# Recovery group-level mean
true_means_s_log_k <- aggregate(df_recovery, true_s_log_k ~ prior_sd + s_log_k_sd + sample, mean)
mean_true_group_level_mean_overall <- mean(true_means_s_log_k$true_s_log_k)
sd_true_group_level_mean_overall <- sd(true_means_s_log_k$true_s_log_k)
mean_true_group_level_mean_0_2 <- mean(true_means_s_log_k[true_means_s_log_k$s_log_k_sd == 0.2, "true_s_log_k"])
sd_true_group_level_mean_0_2 <- sd(true_means_s_log_k[true_means_s_log_k$s_log_k_sd == 0.2, "true_s_log_k"])
mean_true_group_level_mean_0_51 <- mean(true_means_s_log_k[true_means_s_log_k$s_log_k_sd == 0.51, "true_s_log_k"])
sd_true_group_level_mean_0_51 <- sd(true_means_s_log_k[true_means_s_log_k$s_log_k_sd == 0.51, "true_s_log_k"])
mean_true_group_level_mean_0_81 <- mean(true_means_s_log_k[true_means_s_log_k$s_log_k_sd == 0.81, "true_s_log_k"])
sd_true_group_level_mean_0_81 <- sd(true_means_s_log_k[true_means_s_log_k$s_log_k_sd == 0.81, "true_s_log_k"])

true_means_log_k <- aggregate(df_recovery, true_log_k ~ prior_sd + s_log_k_sd + sample, mean)
mean_true_group_level_mean_log_k <- mean(true_means_log_k$true_log_k)
sd_true_group_level_mean_log_k <- sd(true_means_log_k$true_log_k)

true_abs_mean_sample_means_s_log_k <- aggregate(true_means_s_log_k, abs(true_s_log_k) ~ s_log_k_sd, mean)

mean_group_level_mean_overall <- mean(df_results$median_mu_s_log_k)
sd_group_level_mean_overall <- sd(df_results$median_mu_s_log_k)
mean_group_level_mean_0_2 <- mean(df_results[df_results$s_log_k_sd == 0.2, "median_mu_s_log_k"])
sd_group_level_mean_0_2 <- sd(df_results[df_results$s_log_k_sd == 0.2, "median_mu_s_log_k"])
mean_group_level_mean_0_51 <- mean(df_results[df_results$s_log_k_sd == 0.51, "median_mu_s_log_k"])
sd_group_level_mean_0_51 <- sd(df_results[df_results$s_log_k_sd == 0.51, "median_mu_s_log_k"])
mean_group_level_mean_0_81 <- mean(df_results[df_results$s_log_k_sd == 0.81, "median_mu_s_log_k"])
sd_group_level_mean_0_81 <- sd(df_results[df_results$s_log_k_sd == 0.81, "median_mu_s_log_k"])

mean_group_level_mean_log_k <- mean(df_results$median_mu_log_k)
sd_group_level_mean_log_k <- sd(df_results$median_mu_log_k)

# Recovery group-level SD
mean_group_level_sd_0_2 <- mean(df_results[df_results$s_log_k_sd == 0.2, "median_sd_s_log_k"])
sd_group_level_sd_0_2 <- sd(df_results[df_results$s_log_k_sd == 0.2, "median_sd_s_log_k"])
mean_group_level_sd_0_51 <- mean(df_results[df_results$s_log_k_sd == 0.51, "median_sd_s_log_k"])
sd_group_level_sd_0_51 <- sd(df_results[df_results$s_log_k_sd == 0.51, "median_sd_s_log_k"])
mean_group_level_sd_0_81 <- mean(df_results[df_results$s_log_k_sd == 0.81, "median_sd_s_log_k"])
sd_group_level_sd_0_81 <- sd(df_results[df_results$s_log_k_sd == 0.81, "median_sd_s_log_k"])

mean_group_level_sd_log_k <- mean(df_results$median_sd_log_k)
sd_group_level_sd_log_k <- sd(df_results$median_sd_log_k)


# False positive results
fp_savage_dickey_bf_3 <- sum(df_results$fp_savage_dickey_bf_3)/nrow(df_results)

fp_directional_bf_3 <- sum(df_results$fp_directional_bf_3_pos,
                           df_results$fp_directional_bf_1_3_neg)/nrow(df_results)

fp_directional_bf_10 <- sum(df_results$fp_directional_bf_10_pos,
                            df_results$fp_directional_bf_1_10_neg)/nrow(df_results)

fp_directional_bf_30 <- sum(df_results$fp_directional_bf_30_pos,
                            df_results$fp_directional_bf_1_30_neg)/nrow(df_results)

fp_directional_bf_100 <- sum(df_results$fp_directional_bf_100_pos,
                             df_results$fp_directional_bf_1_100_neg)/nrow(df_results)

fp_p_effect_95 <- sum(df_results$fp_p_effect_95_pos,
                      df_results$fp_p_effect_05_neg)/nrow(df_results)

fp_p_effect_975 <- sum(df_results$fp_p_effect_975_pos,
                       df_results$fp_p_effect_025_neg)/nrow(df_results)

fp_p_effect_99 <- sum(df_results$fp_p_effect_99_pos,
                      df_results$fp_p_effect_01_neg)/nrow(df_results)

fp_hdi_80 <- sum(df_results$fp_hdi_80_pos,
                 df_results$fp_hdi_80_neg)/nrow(df_results)

fp_hdi_90 <- sum(df_results$fp_hdi_90_pos,
                 df_results$fp_hdi_90_neg)/nrow(df_results)

fp_hdi_95 <- sum(df_results$fp_hdi_95_pos,
                 df_results$fp_hdi_95_neg)/nrow(df_results)

fp_hdi_99 <- sum(df_results$fp_hdi_99_pos,
                 df_results$fp_hdi_99_neg)/nrow(df_results)

# False positives per prior SD
get_fp_per_prior_sd <- function(column_pos, column_neg){
  prior_sds <- c(0.05, 0.1, 0.2, 0.5, 1, 1.5, 2, 2.5)
  
  vector_fps <- sapply(prior_sds, function(sd){
    sum(df_results[df_results$prior_sd == sd,column_pos],df_results[df_results$prior_sd == sd,column_neg])/600
  })
  
  # Convert to rounded percentages
  sapply(vector_fps, function(proportion){
    format(round(proportion*100, 2), nsmall = 2)
  })
}

fp_savage_dickey_bf_3_priors <- get_fp_per_prior_sd("fp_savage_dickey_bf_3", "")
fp_directional_bf_3_priors <- get_fp_per_prior_sd("fp_directional_bf_3_pos", "fp_directional_bf_1_3_neg")
fp_directional_bf_10_priors <- get_fp_per_prior_sd("fp_directional_bf_10_pos", "fp_directional_bf_1_10_neg")
fp_directional_bf_30_priors <- get_fp_per_prior_sd("fp_directional_bf_30_pos", "fp_directional_bf_1_30_neg")
fp_directional_bf_100_priors <- get_fp_per_prior_sd("fp_directional_bf_100_pos", "fp_directional_bf_1_100_neg")
fp_p_effect_95_priors <- get_fp_per_prior_sd("fp_p_effect_95_pos", "fp_p_effect_05_neg")
fp_p_effect_975_priors <- get_fp_per_prior_sd("fp_p_effect_975_pos", "fp_p_effect_025_neg")
fp_p_effect_99_priors <- get_fp_per_prior_sd("fp_p_effect_99_pos", "fp_p_effect_01_neg")
fp_hdi_80_priors <- get_fp_per_prior_sd("fp_hdi_80_pos", "fp_hdi_80_neg")
fp_hdi_90_priors <- get_fp_per_prior_sd("fp_hdi_90_pos", "fp_hdi_90_neg")
fp_hdi_95_priors <- get_fp_per_prior_sd("fp_hdi_95_pos", "fp_hdi_95_neg")
fp_hdi_99_priors <- get_fp_per_prior_sd("fp_hdi_99_pos", "fp_hdi_99_neg")

# Overlap of false positive results (ofp)
# Number of false positives per method
n_fp_savage_dickey_bf <- sum(df_results$fp_savage_dickey_bf_sim)
n_fp_directional_bf <- sum(df_results$fp_directional_bf_sim_pos, df_results$fp_directional_bf_sim_neg)
n_fp_p_effect <- sum(df_results$fp_p_effect_sim_pos, df_results$fp_p_effect_sim_neg)
n_fp_hdi <- sum(df_results$fp_hdi_sim_pos, df_results$fp_hdi_sim_neg)

ofp_savage_dickey_bf_directional_bf <- sum(df_results$fp_savage_dickey_bf_sim == 1 &
                                             (df_results$fp_directional_bf_sim_pos == 1 |
                                             df_results$fp_directional_bf_sim_neg == 1)) / n_fp_savage_dickey_bf

ofp_savage_dickey_bf_hdi <- sum(df_results$fp_savage_dickey_bf_sim == 1 &
                                  (df_results$fp_hdi_sim_pos == 1 |
                                  df_results$fp_hdi_sim_neg == 1)) / n_fp_savage_dickey_bf

ofp_savage_dickey_bf_p_effect <- sum(df_results$fp_savage_dickey_bf_sim == 1 &
                                       (df_results$fp_p_effect_sim_pos == 1 |
                                       df_results$fp_p_effect_sim_neg == 1)) / n_fp_savage_dickey_bf

ofp_directional_bf_hdi <- sum(df_results$fp_directional_bf_sim_pos == 1 &
                                df_results$fp_hdi_sim_pos == 1,
                              df_results$fp_directional_bf_sim_neg == 1 &
                                df_results$fp_hdi_sim_neg == 1) / n_fp_directional_bf

ofp_directional_bf_p_effect <- sum(df_results$fp_directional_bf_sim_pos == 1 &
                                     df_results$fp_p_effect_sim_pos == 1,
                                   df_results$fp_directional_bf_sim_neg == 1 &
                                     df_results$fp_p_effect_sim_neg == 1) / n_fp_directional_bf

ofp_hdi_p_effect <- sum(df_results$fp_hdi_sim_pos == 1 &
                          df_results$fp_p_effect_sim_pos == 1,
                        df_results$fp_hdi_sim_neg == 1 &
                          df_results$fp_p_effect_sim_neg == 1) / n_fp_hdi


# Median within sample range (mwsr)
get_within_sample_range <- function(column){
  range_vec <- vector()
  for (i in seq(from = 1, by = 8, length.out = length(column)/8)){
    range_vec <- append(range_vec, range(column[seq(i, i+7)])[2] - range(column[seq(i, i+7)])[1])
  }
  return(range_vec)
}

mwsr_savage_dickey_bf <- median(get_within_sample_range(df_results$savage_dickey_bf))
mwsr_directional_bf <- median(get_within_sample_range(df_results$directional_bf))
mwsr_p_effect <- median(get_within_sample_range(df_results$p_effect))

mwsr_iqr_savage_dickey_bf <- IQR(get_within_sample_range(df_results$savage_dickey_bf))
mwsr_iqr_directional_bf <- IQR(get_within_sample_range(df_results$directional_bf))
mwsr_iqr_p_effect <- IQR(get_within_sample_range(df_results$p_effect))


# Prior sensitivity (ps; proportion of samples in which a method came to diverging results)
df_results$fp_directional_bf_sim <- df_results$fp_directional_bf_sim_pos + df_results$fp_directional_bf_sim_neg
df_results$fp_p_effect_sim <- df_results$fp_p_effect_sim_pos + df_results$fp_p_effect_sim_neg
df_results$fp_hdi_sim <- df_results$fp_hdi_sim_pos + df_results$fp_hdi_sim_neg

get_prior_sensitivity <- function(column){
  counter <- 0
  for (i in seq(from = 1, by = 8, length.out = length(column)/8)){
    if (all(column[i] == column[seq(i, i+7)]) == FALSE){
      counter <- counter + 1
    }
  }
  proportion <- counter/(length(column)/8)
  return(proportion)
}

ps_savage_dickey_bf_sim <- get_prior_sensitivity(df_results$fp_savage_dickey_bf_sim)
ps_savage_dickey_bf_sim_0_2 <-get_prior_sensitivity(df_results$fp_savage_dickey_bf_sim[df_results$s_log_k_sd == 0.2])
ps_savage_dickey_bf_sim_0_51 <- get_prior_sensitivity(df_results$fp_savage_dickey_bf_sim[df_results$s_log_k_sd == 0.51])
ps_savage_dickey_bf_sim_0_81 <- get_prior_sensitivity(df_results$fp_savage_dickey_bf_sim[df_results$s_log_k_sd == 0.81])

ps_directional_bf_sim <- get_prior_sensitivity(df_results$fp_directional_bf_sim)
ps_directional_bf_sim_0_2 <- get_prior_sensitivity(df_results$fp_directional_bf_sim[df_results$s_log_k_sd == 0.2])
ps_directional_bf_sim_0_51 <- get_prior_sensitivity(df_results$fp_directional_bf_sim[df_results$s_log_k_sd == 0.51])
ps_directional_bf_sim_0_81 <- get_prior_sensitivity(df_results$fp_directional_bf_sim[df_results$s_log_k_sd == 0.81])

ps_hdi_sim <- get_prior_sensitivity(df_results$fp_hdi_sim)
ps_hdi_sim_0_2 <- get_prior_sensitivity(df_results$fp_hdi_sim[df_results$s_log_k_sd == 0.2])
ps_hdi_sim_0_51 <- get_prior_sensitivity(df_results$fp_hdi_sim[df_results$s_log_k_sd == 0.51])
ps_hdi_sim_0_81 <- get_prior_sensitivity(df_results$fp_hdi_sim[df_results$s_log_k_sd == 0.81])

ps_p_effect_sim <- get_prior_sensitivity(df_results$fp_p_effect_sim)
ps_p_effect_sim_0_2 <- get_prior_sensitivity(df_results$fp_p_effect_sim[df_results$s_log_k_sd == 0.2])
ps_p_effect_sim_0_51 <- get_prior_sensitivity(df_results$fp_p_effect_sim[df_results$s_log_k_sd == 0.51])
ps_p_effect_sim_0_81 <- get_prior_sensitivity(df_results$fp_p_effect_sim[df_results$s_log_k_sd == 0.81])


# Formatting functions
remove_leading_zero <- function(value){
  value <- format(round(value, 2), nsmall = 2)
  value <- gsub("0\\.", ".", value)
  return(value)
}

remove_leading_zero_up <- function(value){
  value <- format(ceiling(value * 10^2) / 10^2, nsmall = 2)
  value <- gsub("0\\.", ".", value)
  return(value)
}

remove_leading_zero_down <- function(value){
  value <- format(floor(value * 10^2) / 10^2, nsmall = 2)
  value <- gsub("0\\.", ".", value)
  return(value)
}

proportion_to_percentage <- function(value){
  value <- format(round(value*100, 2), nsmall = 2)
  return(value)
}

proportion_to_percentage_up <- function(value){
  value <- format(ceiling((value*100) * 10^2) / 10^2, nsmall = 2)
  return(value)
}

round_and_format <- function(value){
  value <- format(round(value, 2), nsmall = 2)
  return(value)
}

round_and_format_up <- function(value){
  value <-  format(ceiling(value * 10^2) / 10^2, nsmall = 2)
  return(value)
}

round_and_format_down <- function(value){
  value <-  format(floor(value * 10^2) / 10^2, nsmall = 2)
  return(value)
}

```

`\section{Results}`  
Note that the intervals between the prior standard deviations are not equal, as they were chosen to cover the most plausible prior standard deviations up to 2.50. Hence, overall means cannot be interpreted continuously as averages of all possible prior standard deviations between 0.05 and 2.50, but as averages of discrete prior variations selected in this study.
<br>
`\subsection{Recovery of subject-level parameters}`  
Subject-level estimates correspond to the medians of the respective posterior distributions. The median correlation between true and estimated subject-level s`\textsubscript{log(\textit{k})}` parameters was `\textit{r}` = `r remove_leading_zero(median_cor_s_log_k_0_2)` (`\textit{IQR}` = `r remove_leading_zero(iqr_cor_s_log_k_0_2)`) within models fitted to samples of the small population effect standard deviation, `\textit{r}` = `r remove_leading_zero(median_cor_s_log_k_0_51)` (`\textit{IQR}` = `r remove_leading_zero(iqr_cor_s_log_k_0_51)`) within models fitted to samples from the medium population effect standard deviation, and `\textit{r}` = `r remove_leading_zero(median_cor_s_log_k_0_81)` (`\textit{IQR}` = `r remove_leading_zero(iqr_cor_s_log_k_0_81)`) within models fitted to samples from the large population effect standard deviation. The median correlation within models over all population effect standard deviations was `\textit{r}` = `r remove_leading_zero(median_cor_s_log_k_overall)` (`\textit{IQR}` = `r remove_leading_zero(iqr_cor_s_log_k_overall)`). The median correlation within models between true and estimated subject-level log(`\textit{k}`) parameters was `\textit{r}` = `r remove_leading_zero(median_cor_log_k_overall)` (`\textit{IQR}` = `r remove_leading_zero(iqr_cor_log_k_overall)`).
`\\`  
Since hierarchical Bayesian models perform partial pooling, the shrinkage of subject-level parameter variability was computed for each model by dividing the difference between the standard deviation of the true subject-level parameters and the standard deviation of the estimated subject-level parameters with the standard deviation of the true subject-level parameters `\autocite{kruschke_doing_2015}`. On average, the standard deviation of true subject-level s`\textsubscript{log(\textit{k})}` parameters was reduced by `r proportion_to_percentage(mean_shrinkage_overall)``\%` (`\textit{SD}` = `r proportion_to_percentage(sd_shrinkage_overall)`) within models. See Figure `\hyperref[fig:recovery]{\ref{fig:recovery}A}` for the ratios of the standard deviations of true and estimated subject-level s`\textsubscript{log(\textit{k})}` parameters within models. Descriptively, shrinkage of the standard deviations of subject-level parameters was stronger, the lower the standard deviation of the sampling distribution was (Table `\ref{tab:shrinkage}`), but constant across all variations of the group-level mean prior of s`\textsubscript{log(\textit{k})}`.
<br>
```
\begin{table}[H]
    \caption{Shrinkage of the standard deviations of subject-level parameters within models}
    \label{tab:shrinkage}
    \begin{tabularx}{\textwidth}{lXXXXXX}
    \midrule
    \multicolumn{1}{c}{Sampling distribution} & \multicolumn{2}{c}{\textit{SD} true parameters} & \multicolumn{2}{c}{\textit{SD} estimates} & \multicolumn{2}{c}{\textit{SD} reduction (\%)}\\
    \cmidrule{2-7}
    \multicolumn{1}{c}{} & \multicolumn{1}{c}{\textit{M}} & \multicolumn{1}{c}{\textit{SD}} & \multicolumn{1}{c}{\textit{M}} & \multicolumn{1}{c}{\textit{SD}} & \multicolumn{1}{c}{\textit{M}} & \multicolumn{1}{c}{\textit{SD}}\\
    \midrule
    s\textsubscript{log(\textit{k})} $\sim \mathcal{N}$(0,0.20) & \centering `r round_and_format(mean_sd_true_0_2)` & \centering `r round_and_format(sd_sd_true_0_2)` & \centering `r round_and_format(mean_sd_estimates_0_2)` & \centering `r round_and_format(sd_sd_estimates_0_2)` & \centering `r proportion_to_percentage(mean_shrinkage_0_2)` & \centering `r  proportion_to_percentage(sd_shrinkage_0_2)`\arraybackslash\\
    s\textsubscript{log(\textit{k})} $\sim \mathcal{N}$(0,0.51) & \centering `r round_and_format(mean_sd_true_0_51)` & \centering `r round_and_format(sd_sd_true_0_51)` & \centering `r round_and_format(mean_sd_estimates_0_51)` & \centering `r round_and_format(sd_sd_estimates_0_51)` & \centering `r proportion_to_percentage(mean_shrinkage_0_51)` & \centering `r proportion_to_percentage(sd_shrinkage_0_51)`\arraybackslash\\
    s\textsubscript{log(\textit{k})} $\sim \mathcal{N}$(0,0.81) & \centering `r round_and_format(mean_sd_true_0_81)` & \centering `r round_and_format(sd_sd_true_0_81)` & \centering `r round_and_format(mean_sd_estimates_0_81)` & \centering `r  round_and_format(sd_sd_estimates_0_81)` & \centering `r proportion_to_percentage(mean_shrinkage_0_81)` & \centering `r proportion_to_percentage(sd_shrinkage_0_81)`\arraybackslash\\
    log(\textit{k}) $\sim \mathcal{N}$(-4.79,1.02) & \centering `r round_and_format(mean_sd_true_overall_log_k)` & \centering `r round_and_format(sd_sd_true_overall_log_k)` & \centering `r round_and_format(mean_sd_estimates_overall_log_k)` & \centering `r  round_and_format(sd_sd_estimates_overall_log_k)` & \centering `r proportion_to_percentage(mean_shrinkage_overall_log_k)` & \centering `r  proportion_to_percentage(sd_shrinkage_overall_log_k)`\arraybackslash\\
    \midrule
    \end{tabularx}
\end{table}
```
<br>
`\subsection{Recovery of group-level parameters}`  
Group-level estimates correspond to the medians of the respective posterior distributions. The mean true group-level mean of s`\textsubscript{log(\textit{k})}` parameters was `r round_and_format(mean_true_group_level_mean_0_2)` (`\textit{SD}` = `r round_and_format(sd_true_group_level_mean_0_2)`) within samples from the small population effect standard deviation, `r round_and_format(mean_true_group_level_mean_0_51)` (`\textit{SD}` = `r round_and_format(sd_true_group_level_mean_0_51)`) within samples from the medium population effect standard deviation, and `r round_and_format(mean_true_group_level_mean_0_81)` (`\textit{SD}` = `r round_and_format(sd_true_group_level_mean_0_81)`) within samples from the large population effect standard deviation. The mean true group-level mean of log(`\textit{k}`) parameters was `r round_and_format(mean_true_group_level_mean_log_k)` (`\textit{SD}` = `r round_and_format(sd_true_group_level_mean_log_k)`). The mean estimate of the group-level mean of s`\textsubscript{log(\textit{k})}` was `r round_and_format(mean_group_level_mean_0_2)` (`\textit{SD}` = `r round_and_format(sd_group_level_mean_0_2)`) within models fitted to samples from the small population effect standard deviation, `r round_and_format(mean_group_level_mean_0_51)` (`\textit{SD}` = `r round_and_format(sd_group_level_mean_0_51)`) within models fitted to samples from the medium population effect standard deviation, and `r round_and_format(mean_group_level_mean_0_81)` (`\textit{SD}` = `r round_and_format(sd_group_level_mean_0_81)`) within models fitted to samples from the large population effect standard deviation. Mean absolute estimates of the group-level mean of s`\textsubscript{log(\textit{k})}` per population effect and prior standard deviation are depicted in Figure `\hyperref[fig:recovery]{\ref{fig:recovery}B}`. Descriptively, mean absolute estimates of the group-level mean were constant with wider priors, but decreased with decreasing prior width. The mean estimate of the group-level mean of log(`\textit{k}`) was `r round_and_format(mean_group_level_mean_log_k)` (`\textit{SD}` = `r round_and_format(sd_group_level_mean_log_k)`).  
`\\`  
The mean estimate of the group-level standard deviation of s`\textsubscript{log(\textit{k})}` was `r round_and_format(mean_group_level_sd_0_2)` (`\textit{SD}` = `r round_and_format(sd_group_level_sd_0_2)`) within models fitted to samples from the small population effect standard deviation, `r round_and_format(mean_group_level_sd_0_51)` (`\textit{SD}` = `r round_and_format(sd_group_level_sd_0_51)`) within models fitted to samples from the medium population effect standard deviation, and `r round_and_format(mean_group_level_sd_0_81)` (`\textit{SD}` = `r round_and_format(sd_group_level_sd_0_81)`) within models fitted to samples from the large population effect standard deviation. The mean estimate of the group-level standard deviation of log(`\textit{k}`) was `r round_and_format(mean_group_level_sd_log_k)` (`\textit{SD}` = `r round_and_format(sd_group_level_sd_log_k)`).
<br>
```
\begin{figure} [H]
    \centering
    \caption{Parameter recovery}
    \label{fig:recovery}
    \includegraphics[width=1\linewidth]{figures/recovery_s_log_k.pdf}
    \caption*{Note. \textnormal{(A) Ratios of the standard deviations of true and estimated subject-level parameters within models. The standard deviations of true subject-level parameters of models below the line were shrunk. Note that absolute shrinkage was comparable between population effect standard deviations, but relative shrinkage was higher, the lower the population effect standard deviation was. (B)  Decrease of absolute group-level mean estimates towards zero with informative priors. Prior standard deviations are plotted on a logarithmic scale. Omitted tick labels are 1.50 and 2.00.}}
\end{figure}
```
<br>
`\subsection{Inference methods}`  
Across all models, Savage-Dickey BFs ranged from `r round_and_format(min(df_results$savage_dickey_bf))` to `r round_and_format(max(df_results$savage_dickey_bf))` (`\textit{Mdn}` = `r round_and_format(median(df_results$savage_dickey_bf))`, `\textit{IQR}` = `r round_and_format(IQR(df_results$savage_dickey_bf))`), dBFs ranged from `r round_and_format(min(df_results$directional_bf))` to `r round_and_format(max(df_results$directional_bf))` (`\textit{Mdn}` = `r round_and_format(median(df_results$directional_bf))`, `\textit{IQR}` = `r round_and_format(IQR(df_results$directional_bf))`), and P(effect > 0) proportions ranged from `r remove_leading_zero(min(df_results$p_effect))` to `r remove_leading_zero(max(df_results$p_effect))` (`\textit{Mdn}` = `r remove_leading_zero(median(df_results$p_effect))`, `\textit{IQR}` = `r remove_leading_zero(IQR(df_results$p_effect))`). Boxplots of Savage-Dickey BFs, dBFs, and P(effect > 0) proportions per prior and population effect standard deviation are shown in Figure `\ref{fig:values}`. With increasing prior width, the median Savage-Dickey BF descriptively decreased, whereas the median dBF and median P(effect > 0) remained constant. The `\textit{IQR}` of dBFs and the `\textit{IQR}` of P(effect > 0) proportions both descriptively increased with increasing prior width, whereas the `\textit{IQR}` of Savage-Dickey BFs was descriptively lower with high prior widths.
<br>
```
\begin{figure} [H]
    \centering
    \caption{Savage-Dickey BFs, dBFs, and P(effect > 0) proportions of all models}
    \label{fig:values}
    \includegraphics[width=1\linewidth]{figures/values.pdf}
    \caption*{Note. \textnormal{The horizontal line within each box shows the median, the box spans from the first to the third quartile, the lower whisker extends to the lowest value within 1.5*\textit{IQR} below the first quartile, the upper whisker extends to the highest value within 1.5*\textit{IQR} above the third quartile, outliers are displayed as dots, which are all data points outside the lower and upper whisker. Savage-Dickey BFs and dBFs are plotted on a logarithmic scale.}}
\end{figure}
```
<br>
`\subsection{False positive results}` 
The proportions of false positive results of every decision rule were calculated for all combinations of the prior and population effect standard deviation (Figure `\ref{fig:false_positves}`), per prior standard deviation averaged over all population effect standard deviations (Table `\ref{tab:false_positives_prior}`),  and overall. With a decision threshold of 3, `r proportion_to_percentage(fp_savage_dickey_bf_3)``\%` of Savage-Dickey BFs were false positive. With a decision threshold of 1/3 for a negative and 3 for a positive effect, `r proportion_to_percentage(fp_directional_bf_3)``\%` of dBFs were false positive. With 1/10 and 10 as directional decision thresholds, `r proportion_to_percentage(fp_directional_bf_10)``\%` of dBFs were false positive, with 1/30 and 30, `r proportion_to_percentage(fp_directional_bf_30)``\%` of dfBFs  were false positive, and with 1/100 and 100, `r proportion_to_percentage(fp_directional_bf_100)``\%` of dBFs  were false positive. When applying the HDI against zero decision rule with a 80`\%` HDI, `r proportion_to_percentage(fp_hdi_80)``\%` of decisions were false positive, with a 90`\%` HDI, `r proportion_to_percentage(fp_hdi_90)``\%` of decisions were false positive, with a 95`\%` HDI, `r proportion_to_percentage(fp_hdi_95)``\%` of decisions were false positive, and with a 99`\%` HDI, `r proportion_to_percentage(fp_hdi_99)``\%` of decisions were false positive. With P(effect > 0) > .95 for a positive and P(effect > 0) < .05 for negative effect, `r proportion_to_percentage(fp_p_effect_95)``\%` of P(effect > 0) proportions were false positive, with > .975 and < .025, `r proportion_to_percentage(fp_p_effect_975)``\%` of P(effect > 0) proportions were false positive, and with > .99 and < .01, `r proportion_to_percentage(fp_p_effect_99)``\%` of P(effect > 0) proportions were false positive. For each inference method, false positive results were lower, the stricter the decision threshold was. False positive results descriptively increased with increasing prior width for all decision thresholds of the dBF, P(effect > 0), and the HDI against zero decision rule, whereas false positive Savage-Dickey BFs did not increase with wider priors. With wider priors and relatively stricter thresholds, false positive results were descriptively higher within samples from the highest population effect standard deviation.
<br>
```
\begin{table}[H]
    \caption{False positive results per prior standard deviation}
    \label{tab:false_positives_prior}
    \begin{tabularx}{\textwidth}{lXXXXXXXX}
    \midrule
    \multicolumn{1}{c}{Decision rule} & \multicolumn{8}{c}{False positive results per prior \textit{SD} (\%)}\\
    \cmidrule{2-9}
    \multicolumn{1}{c}{} & \multicolumn{1}{c}{0.05} & \multicolumn{1}{c}{0.10} & \multicolumn{1}{c}{0.20} & \multicolumn{1}{c}{0.50} & \multicolumn{1}{c}{1.00} & \multicolumn{1}{c}{1.50} & \multicolumn{1}{c}{2.00} & \multicolumn{1}{c}{2.50}\\
    \midrule
    Savage-Dickey BF\textsubscript{10} > 3 & \centering `r fp_savage_dickey_bf_3_priors[1]` & \centering `r fp_savage_dickey_bf_3_priors[2]` & \centering `r fp_savage_dickey_bf_3_priors[3]` & \centering `r fp_savage_dickey_bf_3_priors[4]` & \centering `r fp_savage_dickey_bf_3_priors[5]` & \centering `r fp_savage_dickey_bf_3_priors[6]` & \centering `r fp_savage_dickey_bf_3_priors[7]` & \centering `r fp_savage_dickey_bf_3_priors[8]`\arraybackslash\\
    dBF\textsubscript{+$-$} [1/3, 3] & \centering `r fp_directional_bf_3_priors[1]` & \centering `r fp_directional_bf_3_priors[2]` & \centering `r fp_directional_bf_3_priors[3]` & \centering `r fp_directional_bf_3_priors[4]` & \centering `r fp_directional_bf_3_priors[5]` & \centering `r fp_directional_bf_3_priors[6]` & \centering `r fp_directional_bf_3_priors[7]` & \centering `r fp_directional_bf_3_priors[8]`\arraybackslash\\
    dBF\textsubscript{+$-$} [1/10, 10] & \centering `r fp_directional_bf_10_priors[1]` & \centering `r fp_directional_bf_10_priors[2]` & \centering `r fp_directional_bf_10_priors[3]` & \centering `r fp_directional_bf_10_priors[4]` & \centering `r fp_directional_bf_10_priors[5]` & \centering `r fp_directional_bf_10_priors[6]` & \centering `r fp_directional_bf_10_priors[7]` & \centering `r fp_directional_bf_10_priors[8]`\arraybackslash\\
    dBF\textsubscript{+$-$} [1/30, 30] & \centering `r fp_directional_bf_30_priors[1]` & \centering `r fp_directional_bf_30_priors[2]` & \centering `r fp_directional_bf_30_priors[3]` & \centering `r fp_directional_bf_30_priors[4]` & \centering `r fp_directional_bf_30_priors[5]` & \centering `r fp_directional_bf_30_priors[6]` & \centering `r fp_directional_bf_30_priors[7]` & \centering `r fp_directional_bf_30_priors[8]`\arraybackslash\\
    dBF\textsubscript{+$-$} [1/100, 100] & \centering `r fp_directional_bf_100_priors[1]` & \centering `r fp_directional_bf_100_priors[2]` & \centering `r fp_directional_bf_100_priors[3]` & \centering `r fp_directional_bf_100_priors[4]` & \centering `r fp_directional_bf_100_priors[5]` & \centering `r fp_directional_bf_100_priors[6]` & \centering `r fp_directional_bf_100_priors[7]` & \centering `r fp_directional_bf_100_priors[8]`\arraybackslash\\
    P(effect > 0) [.05, .95] & \centering `r fp_p_effect_95_priors[1]` & \centering `r fp_p_effect_95_priors[2]` & \centering `r fp_p_effect_95_priors[3]` & \centering `r fp_p_effect_95_priors[4]` & \centering `r fp_p_effect_95_priors[5]` & \centering `r fp_p_effect_95_priors[6]` & \centering `r fp_p_effect_95_priors[7]` & \centering `r fp_p_effect_95_priors[8]`\arraybackslash\\
    P(effect > 0) [.025, .975] & \centering `r fp_p_effect_975_priors[1]` & \centering `r fp_p_effect_975_priors[2]` & \centering `r fp_p_effect_975_priors[3]` & \centering `r fp_p_effect_975_priors[4]` & \centering `r fp_p_effect_975_priors[5]` & \centering `r fp_p_effect_975_priors[6]` & \centering `r fp_p_effect_975_priors[7]` & \centering `r fp_p_effect_975_priors[8]`\arraybackslash\\
    P(effect > 0) [.01, .99] & \centering `r fp_p_effect_99_priors[1]` & \centering `r fp_p_effect_99_priors[2]` & \centering `r fp_p_effect_99_priors[3]` & \centering `r fp_p_effect_99_priors[4]` & \centering `r fp_p_effect_99_priors[5]` & \centering `r fp_p_effect_99_priors[6]` & \centering `r fp_p_effect_99_priors[7]` & \centering `r fp_p_effect_99_priors[8]`\arraybackslash\\
    80\% HDI & \centering `r fp_hdi_80_priors[1]` & \centering `r fp_hdi_80_priors[2]` & \centering `r fp_hdi_80_priors[3]` & \centering `r fp_hdi_80_priors[4]` & \centering `r fp_hdi_80_priors[5]` & \centering `r fp_hdi_80_priors[6]` & \centering `r fp_hdi_80_priors[7]` & \centering `r fp_hdi_80_priors[8]`\arraybackslash\\
    90\% HDI & \centering `r fp_hdi_90_priors[1]` & \centering `r fp_hdi_90_priors[2]` & \centering `r fp_hdi_90_priors[3]` & \centering `r fp_hdi_90_priors[4]` & \centering `r fp_hdi_90_priors[5]` & \centering `r fp_hdi_90_priors[6]` & \centering `r fp_hdi_90_priors[7]` & \centering `r fp_hdi_90_priors[8]`\arraybackslash\\
    95\% HDI & \centering `r fp_hdi_95_priors[1]` & \centering `r fp_hdi_95_priors[2]` & \centering `r fp_hdi_95_priors[3]` & \centering `r fp_hdi_95_priors[4]` & \centering `r fp_hdi_95_priors[5]` & \centering `r fp_hdi_95_priors[6]` & \centering `r fp_hdi_95_priors[7]` & \centering `r fp_hdi_95_priors[8]`\arraybackslash\\
    99\% HDI & \centering `r fp_hdi_99_priors[1]` & \centering `r fp_hdi_99_priors[2]` & \centering `r fp_hdi_99_priors[3]` & \centering `r fp_hdi_99_priors[4]` & \centering `r fp_hdi_99_priors[5]` & \centering `r fp_hdi_99_priors[6]` & \centering `r fp_hdi_99_priors[7]` & \centering `r fp_hdi_99_priors[8]`\arraybackslash\\
    \midrule
    \end{tabularx}
\end{table}
```
```
\begin{figure} [H]
    \centering
    \caption{Proportions of false positive results with conventional decision thresholds}
    \label{fig:false_positves}
    \includegraphics[width=1\linewidth]{figures/false_positives.pdf}
    \caption*{Note. \textnormal{Dashed lines indicate a proportion of 5\% false positive results. Prior standard deviations are plotted on a logarithmic scale. Omitted tick labels are 0.10, 0.50, 1.50, and 2.00.}}
\end{figure}
```
<br>
`\subsection{Simulation-based decision thresholds}`  
Simulation-based decision thresholds with a proportion of 5`\%` false positive results were computed for every inference method for all combinations of the prior and population effect standard deviation (Figure `\ref{fig:sim_thres}`), per prior standard deviation averaged over all population effect standard deviations (Table `\ref{tab:sim_thres_prior}`), and overall. Upper thresholds were rounded up, lower thresholds were rounded down. Directional thresholds were set to 2.5`\%` false positive results on each side. With a decision threshold of `r round_and_format_up(sim_based_thres$savage_dickey_bf[1])`, 5`\%` of Savage Dickey BFs were false positive. The dBF produced 5`\%` false positive results with a decision threshold of `r round_and_format_up(sim_based_thres$directional_bf_upper[1])` for a positive and 1/`r round_and_format_up(1/sim_based_thres$directional_bf_lower[1])` for a negative effect. A decision rule of P(effect > 0) > `r remove_leading_zero_up(sim_based_thres$p_effect_upper[1])` for a positive and P(effect > 0) < `r remove_leading_zero_down(sim_based_thres$p_effect_lower[1])` for a negative effect resulted in 5`\%` false positive results. The HDI against zero decision rule produced 5`\%` false positive results with a `r proportion_to_percentage_up(sim_based_thres$hdi[1])``\%` HDI. Simulation-based decision thresholds of the dBF, P(effect > 0), and the HDI against zero decision rule became descriptively stricter with increasing prior width, whereas the simulation-based threshold of the Savage-Dickey BF was the lowest with the widest prior. Adjustments of simulation-based decision thresholds for multiple tests under the assumption of statistical independence are shown in Figure `\ref{fig:thresholds}`.
<br>
```
\begin{figure} [H]
    \centering
    \caption{Simulation-based decision thresholds}
    \label{fig:sim_thres}
    \includegraphics[width=1\linewidth]{figures/sim_thres.pdf}
    \caption*{Note. \textnormal{Prior standard deviations are plotted on a logarithmic scale. Omitted tick labels are 0.10, 0.50, 1.50, and 2.00.}}
\end{figure}
```

```
\begin{table}[H]
    \caption{Simulation-based decision thresholds per prior standard deviation}
    \label{tab:sim_thres_prior}
    \begin{tabularx}{\textwidth}{lXXXXXXXX}
    \midrule
    \multicolumn{1}{c}{Inference method} & \multicolumn{8}{c}{Simulation-based decision threshold per prior \textit{SD}}\\
    \cmidrule{2-9}
    \multicolumn{1}{c}{} & \multicolumn{1}{c}{0.05} & \multicolumn{1}{c}{0.10} & \multicolumn{1}{c}{0.20} & \multicolumn{1}{c}{0.50} & \multicolumn{1}{c}{1.00} & \multicolumn{1}{c}{1.50} & \multicolumn{1}{c}{2.00} & \multicolumn{1}{c}{2.50}\\
    \midrule
    Savage-Dickey BF\textsubscript{10} & \centering `r round_and_format_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.05,"savage_dickey_bf"])` & \centering `r round_and_format_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.1,"savage_dickey_bf"])` & \centering `r round_and_format_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.2,"savage_dickey_bf"])` & \centering `r round_and_format_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.5,"savage_dickey_bf"])` & \centering `r round_and_format_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 1,"savage_dickey_bf"])` & \centering `r round_and_format_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 1.5,"savage_dickey_bf"])` & \centering `r round_and_format_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 2,"savage_dickey_bf"])` & \centering `r round_and_format_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 2.5,"savage_dickey_bf"])`\arraybackslash\\
    dBF\textsubscript{+$-$} (upper) & \centering `r round_and_format_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.05,"directional_bf_upper"])` & \centering `r round_and_format_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.1,"directional_bf_upper"])` & \centering `r round_and_format_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.2,"directional_bf_upper"])` & \centering `r round_and_format_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.5,"directional_bf_upper"])` & \centering `r round_and_format_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 1,"directional_bf_upper"])` & \centering `r round_and_format_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 1.5,"directional_bf_upper"])` & \centering `r round_and_format_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 2,"directional_bf_upper"])` & \centering `r round_and_format_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 2.5,"directional_bf_upper"])`\arraybackslash\\
    dBF\textsubscript{+$-$} (lower) & \centering 1/`r round_and_format_up(1/df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.05,"directional_bf_lower"])` & \centering 1/`r round_and_format_up(1/df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.1,"directional_bf_lower"])` & \centering 1/`r round_and_format_up(1/df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.2,"directional_bf_lower"])` & \centering 1/`r round_and_format_up(1/df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.5,"directional_bf_lower"])` & \centering 1/`r round_and_format_up(1/df_sim_thres_prior[df_sim_thres_prior$prior_sd == 1,"directional_bf_lower"])` & \centering 1/`r round_and_format_up(1/df_sim_thres_prior[df_sim_thres_prior$prior_sd == 1.5,"directional_bf_lower"])` & \centering 1/`r round_and_format_up(1/df_sim_thres_prior[df_sim_thres_prior$prior_sd == 2,"directional_bf_lower"])` & \centering 1/`r round_and_format_up(1/df_sim_thres_prior[df_sim_thres_prior$prior_sd == 2.5,"directional_bf_lower"])`\arraybackslash\\
    P(effect > 0) (upper) & \centering `r remove_leading_zero_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.05,"p_effect_upper"])` & \centering `r remove_leading_zero_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.1,"p_effect_upper"])` & \centering `r remove_leading_zero_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.2,"p_effect_upper"])` & \centering `r remove_leading_zero_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.5,"p_effect_upper"])` & \centering `r remove_leading_zero_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 1,"p_effect_upper"])` & \centering `r remove_leading_zero_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 1.5,"p_effect_upper"])` & \centering `r remove_leading_zero_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 2,"p_effect_upper"])` & \centering `r remove_leading_zero_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 2.5,"p_effect_upper"])`\arraybackslash\\
    P(effect > 0) (lower) & \centering `r remove_leading_zero_down(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.05,"p_effect_lower"])` & \centering `r remove_leading_zero_down(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.1,"p_effect_lower"])` & \centering `r remove_leading_zero_down(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.2,"p_effect_lower"])` & \centering `r remove_leading_zero_down(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.5,"p_effect_lower"])` & \centering `r remove_leading_zero_down(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 1,"p_effect_lower"])` & \centering `r remove_leading_zero_down(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 1.5,"p_effect_lower"])` & \centering `r remove_leading_zero_down(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 2,"p_effect_lower"])` & \centering `r remove_leading_zero_down(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 2.5,"p_effect_lower"])`\arraybackslash\\
    HDI width (\%) & \centering `r proportion_to_percentage_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.05,"hdi"])` & \centering `r proportion_to_percentage_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.1,"hdi"])` & \centering `r proportion_to_percentage_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.2,"hdi"])` & \centering `r proportion_to_percentage_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 0.5,"hdi"])` & \centering `r proportion_to_percentage_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 1,"hdi"])` & \centering `r proportion_to_percentage_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 1.5,"hdi"])` & \centering `r proportion_to_percentage_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 2,"hdi"])` & \centering `r proportion_to_percentage_up(df_sim_thres_prior[df_sim_thres_prior$prior_sd == 2.5,"hdi"])`\arraybackslash\\
    \midrule
    \end{tabularx}
\end{table}
```

```
\begin{figure} [H]
    \centering
    \caption{Adjustments of simulation-based decision thresholds for multiple testing}
    \label{fig:thresholds_multiple_test}
    \includegraphics[width=1\linewidth]{figures/thresholds_multiple_tests.pdf}
\end{figure}
```
<br>
`\subsubsection{Overlap of false positive results}`  
With simulation-based decision thresholds, `r proportion_to_percentage(ofp_savage_dickey_bf_directional_bf)``\%` of false positive Savage-Dickey BFs overlapped with false positive dBFs, `r proportion_to_percentage(ofp_savage_dickey_bf_hdi)``\%` overlapped with false positive HDI decisions and `r proportion_to_percentage(ofp_savage_dickey_bf_p_effect)``\%` overlapped with false positive P(effect > 0) proportions. `r proportion_to_percentage(ofp_directional_bf_hdi)``\%` of false positive dBFs overlapped with false positive HDI decisions and `r proportion_to_percentage(ofp_directional_bf_p_effect)``\%` overlapped with false positive P(effect > 0) proportions. `r proportion_to_percentage(ofp_hdi_p_effect)``\%` of false positive HDI decisions overlapped with false positive P(effect > 0) proportions.
<br>
`\subsubsection{Prior sensitivity}`  
The prior sensitivity of the Savage-Dickey BF, dBF, and P(effect > 0) was assessed by calculating the median range of the respective inference method between the models within samples. The median range of Savage-Dickey BFs  within samples was `r round_and_format(mwsr_savage_dickey_bf)` (`\textit{IQR}` = `r round_and_format(mwsr_iqr_savage_dickey_bf)`), the median range of dBFs within samples was `r round_and_format(mwsr_directional_bf)` (`\textit{IQR}` = `r round_and_format(mwsr_iqr_directional_bf)`), and the median range of P(effect > 0) proportions within samples was `r round_and_format(mwsr_p_effect)` (`\textit{IQR}` = `r round_and_format(mwsr_iqr_p_effect)`).  
`\\`  
To assess the prior sensitivity of the inference methods in terms of the hypothesis decision, the respective proportions of samples for which the decisions of an inference method diverged between models was calculated. The simulation-based decision thresholds over all prior and population effect standard deviations were choosen to keep the total number of false positive results comparable. With simulation-based decision thresholds, the Savage-Dickey BF came to diverging results due to different priors within `r proportion_to_percentage(ps_savage_dickey_bf_sim)``\%` of all samples. The dBF produced inconsistent results within `r proportion_to_percentage(ps_directional_bf_sim)``\%` of all samples. The HDI against zero decision rule came to different results within `r proportion_to_percentage(ps_hdi_sim)``\%` of all samples and P(effect > 0) came to diverging results within `r proportion_to_percentage(ps_p_effect_sim)``\%` of all samples. See Table `\ref{tab:prior_sensitivity}` for the prior sensitivities per population effect standard deviations. The prior sensitivity of the Savage-Dickey BF slightly decreased descriptively with increasing standard deviation of the population effect, whereas the prior sensitivity of the dBF, P(effect > 0), and the HDI against zero decision rule descriptively increased with increasing population effect standard deviation.
<br>
```
\begin{table}[H]
    \caption{Prior sensitivity of each inference method per population effect standard deviation}
    \label{tab:prior_sensitivity}
    \begin{tabularx}{\textwidth}{lXXX}
    \midrule
    \multicolumn{1}{c}{Inference method} & \multicolumn{3}{c}{Samples with diverging results per population effect \textit{SD} (\%)}\\
    \cmidrule{2-4}
    \multicolumn{1}{c}{} & \multicolumn{1}{c}{0.20} & \multicolumn{1}{c}{0.51} & \multicolumn{1}{c}{0.81}\\
    \midrule
    Savage-Dickey BF\textsubscript{10} & \centering `r proportion_to_percentage(ps_savage_dickey_bf_sim_0_2)` & \centering `r proportion_to_percentage(ps_savage_dickey_bf_sim_0_51)` & \centering `r proportion_to_percentage(ps_savage_dickey_bf_sim_0_81)`\arraybackslash\\
    dBF\textsubscript{+$-$} & \centering `r proportion_to_percentage(ps_directional_bf_sim_0_2)` & \centering `r proportion_to_percentage(ps_directional_bf_sim_0_51)` & \centering `r proportion_to_percentage(ps_directional_bf_sim_0_81)`\arraybackslash\\
    95\% HDI & \centering `r proportion_to_percentage(ps_hdi_sim_0_2)` & \centering `r proportion_to_percentage(ps_hdi_sim_0_51)` & \centering `r proportion_to_percentage(ps_hdi_sim_0_81)`\arraybackslash\\
    P(effect > 0) & \centering `r proportion_to_percentage(ps_p_effect_sim_0_2)` & \centering `r proportion_to_percentage(ps_p_effect_sim_0_51)` & \centering `r proportion_to_percentage(ps_p_effect_sim_0_81)`\arraybackslash\\
    \midrule
    \end{tabularx}
\end{table}
```
<br>
